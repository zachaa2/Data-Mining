{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3353e934",
   "metadata": {},
   "source": [
    "# Assign7: RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b898f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import copy\n",
    "import random\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8790dd3",
   "metadata": {},
   "source": [
    "### Reading in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "275db394",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./Train_Arabic_Digit.txt\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f7e2b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "point = []\n",
    "for line in f:\n",
    "    if line.isspace() == True and len(point) > 0:\n",
    "        dataset.append(copy.deepcopy(point))\n",
    "        point = []\n",
    "    else:\n",
    "        if line.isspace() == False:\n",
    "            line_list = line.strip().split()\n",
    "            line_float = [ float(x) for x in line_list ]\n",
    "            point.append(line_float)\n",
    "dataset.append(copy.deepcopy(point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb1138a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c29308cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6600"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1e19f9",
   "metadata": {},
   "source": [
    "### Reading in testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6324fcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./Test_Arabic_Digit.txt\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ed3d966",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = []\n",
    "point = []\n",
    "for line in f:\n",
    "    if line.isspace() == True and len(point) > 0:\n",
    "        testset.append(copy.deepcopy(point))\n",
    "        point = []\n",
    "    else:\n",
    "        if line.isspace() == False:\n",
    "            line_list = line.strip().split()\n",
    "            line_float = [ float(x) for x in line_list ]\n",
    "            point.append(line_float)\n",
    "testset.append(copy.deepcopy(point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0964ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "080e0853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df6af66",
   "metadata": {},
   "source": [
    "### Making the ground truth labels according to documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9960ded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "y_test = []\n",
    "for i in range(10):\n",
    "    for j in range(660):\n",
    "        y_train.append(i)\n",
    "        \n",
    "for i in range(10):\n",
    "    for j in range(220):\n",
    "        y_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5578848b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6600"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53358fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e088a3fe",
   "metadata": {},
   "source": [
    "### Create One-Hot Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8916030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a one hot encoding of the target labels\n",
    "y = np.zeros( (len(y_train), max(y_train) + 1) )\n",
    "y[np.arange(len(y_train)), y_train] = 1\n",
    "y_train = copy.deepcopy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "868fc74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a one hot encoding of the target labels\n",
    "y = np.zeros( (len(y_test), max(y_test) + 1) )\n",
    "y[np.arange(len(y_test)), y_test] = 1\n",
    "y_test = copy.deepcopy(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4563161",
   "metadata": {},
   "source": [
    "# RNN Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1420a8",
   "metadata": {},
   "source": [
    "### ReLU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9594c9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return (np.maximum(0, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bffe0a6",
   "metadata": {},
   "source": [
    "### Softmax derivative function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "79b3309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_softmax(x):\n",
    "    df = []\n",
    "    for i in range(len(x)):\n",
    "        val = x[i] * (1 - x[i])\n",
    "        df.append(val)\n",
    "    df = np.array(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3708b809",
   "metadata": {},
   "source": [
    "### ReLU derivative function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1917a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_relu(x):\n",
    "    df = []\n",
    "    for i in range(len(x)):\n",
    "        if x[i] <= 0:\n",
    "            df.append(0)\n",
    "        else:\n",
    "            df.append(1)\n",
    "    df = np.array(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc6d882",
   "metadata": {},
   "source": [
    "### Training Step Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "04f16950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_Training(x, y):\n",
    "    # define some constants\n",
    "    maxiter = 40\n",
    "    d = 13\n",
    "    m = 16\n",
    "    p = 10\n",
    "    eta = 1e-5\n",
    "    # hidden layer activation function - ReLU\n",
    "    # output layer activation function - softmax\n",
    "    \n",
    "    final_output = []\n",
    "    final_ground_truth = []\n",
    "    final_loss = []\n",
    "    # initialize bias vectors\n",
    "    bh = np.random.rand(m)\n",
    "    bh = bh * 0.1\n",
    "    bo = np.random.rand(p)\n",
    "    bo = bo * 0.1\n",
    "    #initialize weight matrices\n",
    "    Wi = np.random.rand(d, m)\n",
    "    Wi = Wi * 0.1\n",
    "    Wh = np.random.rand(m, m)\n",
    "    Wh = Wh * 0.1\n",
    "    Wo = np.random.rand(m, p)\n",
    "    Wo = Wo * 0.1\n",
    "    # iteration counter\n",
    "    r = 0\n",
    "    \n",
    "    while (r < maxiter):\n",
    "        final_output = []\n",
    "        final_ground_truth = []\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # iterate through dataset in random order\n",
    "        s = list(range(len(x)))\n",
    "        random.shuffle(s)\n",
    "        for i in s:\n",
    "            \n",
    "            ### FEED FORWARD PHASE ###\n",
    "            sequence = x[i]\n",
    "            tau = len(sequence)\n",
    "            \n",
    "            # initialize hidden state\n",
    "            h = np.zeros((tau, m))\n",
    "            # iteratively calculate hidden state\n",
    "            for j in range(tau):\n",
    "                t1 = np.dot(Wi.T, sequence[j]) + np.dot(Wh.T, h[j-1]) + bh\n",
    "                h[j] = relu(t1)\n",
    "            # compute output layer\n",
    "            o = softmax(np.dot(Wo.T, h[tau-1]) + bo)\n",
    "            \n",
    "            # if it's the final iteration, save the softmax output and truth labels\n",
    "            #if r == maxiter-1:\n",
    "            if True:    \n",
    "                final_output.append(o.copy())\n",
    "                final_ground_truth.append(copy.deepcopy(y[i]))\n",
    "            \n",
    "            # calculate final loss for each data point \n",
    "            if r == maxiter - 1:\n",
    "                summ = 0\n",
    "                for j in range(p):\n",
    "                    prod = y[i][j] * np.log(o[j])\n",
    "                    summ += prod\n",
    "                summ = -1 * summ\n",
    "                final_loss.append(summ)\n",
    "                \n",
    "                \n",
    "            ### BACK PROP PHASE ###\n",
    "            derivative_loss = o - y[i]\n",
    "            derivative_softmax = df_softmax(o)\n",
    "            # net gradients at output\n",
    "            delta_o = derivative_softmax * derivative_loss \n",
    "            # get delta at tau\n",
    "            t2 = np.dot(Wo, delta_o)\n",
    "            derivative_relu = df_relu(h[tau-1])\n",
    "            delta_tau = derivative_relu * t2\n",
    "            # net gradients at hidden layer\n",
    "            # computed iteratively\n",
    "            delta_h = np.zeros((tau, m))\n",
    "            delta_h[tau-1] = delta_tau\n",
    "            for j in range(tau-2, -1, -1):\n",
    "                hidden_partial = df_relu(h[j])\n",
    "                t3 = np.dot(Wh, delta_h[j+1])\n",
    "                net_grad = hidden_partial * t3\n",
    "                delta_h[j] = net_grad\n",
    "            \n",
    "            # now get the gradients of weights matrices and bias vectors\n",
    "            gradient_bo = delta_o.copy()\n",
    "            \n",
    "            gradient_wo = np.zeros((m, p))\n",
    "            prod = np.outer(h[tau-1], delta_o)\n",
    "            gradient_wo += prod\n",
    "            \n",
    "            gradient_bh = np.zeros(m)\n",
    "            for j in range(tau):\n",
    "                gradient_bh += delta_h[j]\n",
    "                \n",
    "            gradient_wh = np.zeros((m, m))\n",
    "            for j in range(tau):\n",
    "                prod = np.outer(h[j-1], delta_h[j])\n",
    "                gradient_wh += prod\n",
    "                \n",
    "            gradient_wi = np.zeros((d, m))\n",
    "            for j in range(tau):\n",
    "                prod = np.outer(sequence[j], delta_h[j])\n",
    "                gradient_wi += prod\n",
    "            \n",
    "            # gradient descent\n",
    "            bo = bo - eta * gradient_bo\n",
    "            Wo = Wo - eta * gradient_wo\n",
    "            bh = bh - eta * gradient_bh\n",
    "            Wh = Wh - eta * gradient_wh\n",
    "            Wi = Wi - eta * gradient_wi\n",
    "            \n",
    "        \n",
    "        \n",
    "        r += 1\n",
    "        print(\"EPOCH:\", r, \"Time:\", round(time.time()-start_time, 2), \"seconds\")\n",
    "    \n",
    "        # compute the accuracy\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i in range(len(final_output)):\n",
    "            pred = np.argmax(final_output[i])\n",
    "            actual = np.argmax(final_ground_truth[i])\n",
    "            if pred == actual:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "        acc = correct / total\n",
    "        print(\"Accuracy Score: \", acc)\n",
    "    \n",
    "    avg_loss = np.mean(final_loss)\n",
    "    print(\"Average Cross Entropy Loss:\", avg_loss)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e533bf",
   "metadata": {},
   "source": [
    "### RNN On Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "90dd75c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1 Time: 5.65 seconds\n",
      "Accuracy Score:  0.10333333333333333\n",
      "EPOCH: 2 Time: 5.44 seconds\n",
      "Accuracy Score:  0.10333333333333333\n",
      "EPOCH: 3 Time: 5.44 seconds\n",
      "Accuracy Score:  0.10333333333333333\n",
      "EPOCH: 4 Time: 5.43 seconds\n",
      "Accuracy Score:  0.10333333333333333\n",
      "EPOCH: 5 Time: 5.44 seconds\n",
      "Accuracy Score:  0.10333333333333333\n",
      "EPOCH: 6 Time: 5.66 seconds\n",
      "Accuracy Score:  0.10333333333333333\n",
      "EPOCH: 7 Time: 5.56 seconds\n",
      "Accuracy Score:  0.10333333333333333\n",
      "EPOCH: 8 Time: 5.49 seconds\n",
      "Accuracy Score:  0.10333333333333333\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [92]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mRNN_Training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [91]\u001b[0m, in \u001b[0;36mRNN_Training\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# now get the gradients of weights matrices and bias vectors\u001b[39;00m\n\u001b[0;32m     77\u001b[0m gradient_bo \u001b[38;5;241m=\u001b[39m delta_o\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 79\u001b[0m gradient_wo \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m prod \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mouter(h[tau\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], delta_o)\n\u001b[0;32m     81\u001b[0m gradient_wo \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prod\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RNN_Training(dataset, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb95edf",
   "metadata": {},
   "source": [
    "### RNN On Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0979f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1 Time: 1.86 seconds\n",
      "Accuracy Score:  0.09909090909090909\n",
      "EPOCH: 2 Time: 1.93 seconds\n",
      "Accuracy Score:  0.09909090909090909\n",
      "EPOCH: 3 Time: 2.12 seconds\n",
      "Accuracy Score:  0.09909090909090909\n",
      "EPOCH: 4 Time: 1.86 seconds\n",
      "Accuracy Score:  0.09909090909090909\n",
      "EPOCH: 5 Time: 1.84 seconds\n",
      "Accuracy Score:  0.09909090909090909\n",
      "EPOCH: 6 Time: 1.86 seconds\n",
      "Accuracy Score:  0.09909090909090909\n",
      "EPOCH: 7 Time: 1.86 seconds\n",
      "Accuracy Score:  0.09909090909090909\n",
      "EPOCH: 8 Time: 1.83 seconds\n",
      "Accuracy Score:  0.09909090909090909\n",
      "EPOCH: 9 Time: 1.86 seconds\n",
      "Accuracy Score:  0.09909090909090909\n",
      "EPOCH: 10 Time: 1.8 seconds\n",
      "Accuracy Score:  0.09909090909090909\n",
      "EPOCH: 11 Time: 1.81 seconds\n",
      "Accuracy Score:  0.09954545454545455\n",
      "EPOCH: 12 Time: 1.8 seconds\n",
      "Accuracy Score:  0.09954545454545455\n",
      "EPOCH: 13 Time: 1.82 seconds\n",
      "Accuracy Score:  0.09954545454545455\n",
      "EPOCH: 14 Time: 1.82 seconds\n",
      "Accuracy Score:  0.1\n",
      "EPOCH: 15 Time: 1.8 seconds\n",
      "Accuracy Score:  0.1\n",
      "EPOCH: 16 Time: 1.82 seconds\n",
      "Accuracy Score:  0.1\n",
      "EPOCH: 17 Time: 1.8 seconds\n",
      "Accuracy Score:  0.1\n",
      "EPOCH: 18 Time: 1.81 seconds\n",
      "Accuracy Score:  0.1\n",
      "EPOCH: 19 Time: 1.8 seconds\n",
      "Accuracy Score:  0.1\n",
      "EPOCH: 20 Time: 1.8 seconds\n",
      "Accuracy Score:  0.1\n",
      "EPOCH: 21 Time: 1.81 seconds\n",
      "Accuracy Score:  0.1009090909090909\n",
      "EPOCH: 22 Time: 1.84 seconds\n",
      "Accuracy Score:  0.1009090909090909\n",
      "EPOCH: 23 Time: 1.8 seconds\n",
      "Accuracy Score:  0.10136363636363636\n",
      "EPOCH: 24 Time: 1.81 seconds\n",
      "Accuracy Score:  0.10136363636363636\n",
      "EPOCH: 25 Time: 1.81 seconds\n",
      "Accuracy Score:  0.10136363636363636\n"
     ]
    }
   ],
   "source": [
    "RNN_Training(testset, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6dd128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d43cddc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
